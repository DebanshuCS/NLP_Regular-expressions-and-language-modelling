{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**NLP**, To study interesting patterns, and write up the regexes that describe those patterns, some example results, and an explanation for why they're interesting. Some examples include \n",
        "*   (1) common morphological suffixes,\n",
        "*   (2) patterns that indicate proper names,\n",
        "\n",
        "*    (3) patterns that indicate\n",
        "verbs, etc *italicized text*.\n",
        "\n",
        "\n",
        "\n",
        "  Tokenize the text file and mention the counts of top 10 words excluding stop words. \n",
        "\n"
      ],
      "metadata": {
        "id": "eSrDQ5pxVuZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af-2BQZKMx2u"
      },
      "outputs": [],
      "source": [
        "# This is the URL I am going to use https://gutenberg.org/files/1342/1342-0.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add text file \n",
        "text_file=open(\"/content/nlptext.txt\",\"r\")\n",
        "data=text_file.read()\n",
        "text_file.close()"
      ],
      "metadata": {
        "id": "tuvXJL6iNZaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "j-sMHAAbT9Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import nltk, re, pprint"
      ],
      "metadata": {
        "id": "WpbbGrNgPC7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "tNzxZGi9SIYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)\n"
      ],
      "metadata": {
        "id": "0_VjUzBdTbgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "6RVm_uxeTfHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(data)"
      ],
      "metadata": {
        "id": "FNIGnBnvThf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokens)"
      ],
      "metadata": {
        "id": "GUAq8nldUeII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "id": "fHDg_0-tUgvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "id": "gVS70R_tUnhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(tokens)\n",
        "type(text)"
      ],
      "metadata": {
        "id": "VvQN4CeLUqSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[100:120]"
      ],
      "metadata": {
        "id": "gCF5vfX4UqUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_endings = r\"[.?!]\"\n",
        "print(re.split(sentence_endings, data))"
      ],
      "metadata": {
        "id": "LlB31Nt0UqWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capitalized_words = r\"[A-Z]\\w+\"\n",
        "print(re.findall(capitalized_words, data))"
      ],
      "metadata": {
        "id": "kqCMqSj9U5Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spaces = r\"\\s+\"\n",
        "print(re.split(spaces, data))"
      ],
      "metadata": {
        "id": "3ABUsVDlU5RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits = r\"\\d+\"\n",
        "print(re.findall(digits, data))"
      ],
      "metadata": {
        "id": "UPdrG_AhVDeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "qpE2lHuXVIjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=word_tokenize(data)"
      ],
      "metadata": {
        "id": "NYdqWDBSVN2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "wordlist = [w for w in words if w.islower()]"
      ],
      "metadata": {
        "id": "7CqrYgerVPW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlist"
      ],
      "metadata": {
        "id": "zRAgxvIQVRM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[w for w in wordlist if re.search('ed$', w)]"
      ],
      "metadata": {
        "id": "tYmpmkR8VU9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(word):\n",
        "\n",
        "  for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
        "    if word.endswith(suffix):\n",
        "      return word[:-len(suffix)]\n",
        "  return word\n",
        "stem(data)"
      ],
      "metadata": {
        "id": "2rCTies8VXhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "PdVrvghMVcRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_it=data.split()\n",
        "split_it\n",
        "counter=Counter(split_it)\n",
        "most_occur = counter.most_common(10)\n",
        "  \n",
        "print(most_occur)"
      ],
      "metadata": {
        "id": "WYgVSWMUVeLN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}